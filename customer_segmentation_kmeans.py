# -*- coding: utf-8 -*-
"""Customer_Segmentation_KMeans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g_5DVfovQD-gznns8ypHbsZSWQ02wwi_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from google.colab import files
import io

print("=== CUSTOMER SEGMENTATION USING K-MEANS ===")

uploaded = files.upload()
file_name = list(uploaded.keys())[0]
df = pd.read_csv(io.BytesIO(uploaded[file_name]))

print("Dataset uploaded successfully!")
print(f"Shape: {df.shape}")
print("\nFirst 5 rows:")
print(df.head())

print("=== DATA PREPROCESSING ===")

# Correct feature names
features = ['Annual Income (k$)', 'Spending Score (1-100)']

# Verify features exist
print("Available columns:", df.columns.tolist())
print("Selected features:", features)

# Extract and scale features
X = df[features]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print(f"Original data shape: {X.shape}")
print(f"Scaled data shape: {X_scaled.shape}")
print("Data preprocessing completed! âœ“")

print("=== ELBOW METHOD ===")

wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# Plot elbow curve
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss, marker='o', linestyle='--', color='blue', linewidth=2)
plt.title('Elbow Method for Optimal K', fontsize=14, fontweight='bold')
plt.xlabel('Number of Clusters')
plt.ylabel('Within-Cluster Sum of Squares (WCSS)')
plt.xticks(range(1, 11))
plt.grid(True, alpha=0.3)
plt.show()

print("WCSS Values:")
for i, val in enumerate(wcss, 1):
    print(f"Clusters: {i}, WCSS: {val:.2f}")

print("=== APPLYING K-MEANS ===")

optimal_k = 5  # Based on elbow method
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
df['Cluster'] = kmeans.fit_predict(X_scaled)

print("Clustering completed!")
print("\nCluster distribution:")
cluster_counts = df['Cluster'].value_counts().sort_index()
for cluster, count in cluster_counts.items():
    percentage = (count / len(df)) * 100
    print(f"Cluster {cluster}: {count} customers ({percentage:.1f}%)")

# Step 6: Visualize Clusters - CORRECTED
print("=== CLUSTER VISUALIZATION ===")

plt.figure(figsize=(12, 8))
colors = ['red', 'blue', 'green', 'purple', 'orange']

for i in range(optimal_k):
    cluster_data = df[df['Cluster'] == i]
    plt.scatter(cluster_data['Annual Income (k$)'],
                cluster_data['Spending Score (1-100)'],
                c=colors[i], label=f'Cluster {i}', alpha=0.7, s=60)

plt.title('Customer Segments - Annual Income vs Spending Score', fontsize=14, fontweight='bold')
plt.xlabel('Annual Income (k$)', fontsize=12)
plt.ylabel('Spending Score (1-100)', fontsize=12)
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

print("=== CLUSTER ANALYSIS ===")

# Detailed cluster analysis
cluster_summary = df.groupby('Cluster').agg({
    features[0]: ['count', 'mean', 'std', 'min', 'max'],
    features[1]: ['mean', 'std', 'min', 'max']
}).round(2)

print("Cluster Summary:")
print(cluster_summary)
print("\n" + "="*50)

# Customer count per cluster
print("\nCustomers per Cluster:")
cluster_counts = df['Cluster'].value_counts().sort_index()
for cluster, count in cluster_counts.items():
    percentage = (count / len(df)) * 100
    print(f"Cluster {cluster}: {count} customers ({percentage:.1f}%)")

print("=== CUSTOMER PROFILES ===")

profiles = []
for cluster in range(optimal_k):
    cluster_data = df[df['Cluster'] == cluster]

    profile = {
        'Cluster': cluster,
        'Size': len(cluster_data),
        'Percentage': (len(cluster_data) / len(df)) * 100,
        f'Avg_{features[0]}': cluster_data[features[0]].mean(),
        f'Avg_{features[1]}': cluster_data[features[1]].mean(),
        'Income_Range': f"{cluster_data[features[0]].min():.0f}-{cluster_data[features[0]].max():.0f}",
        'Spending_Range': f"{cluster_data[features[1]].min():.0f}-{cluster_data[features[1]].max():.0f}"
    }
    profiles.append(profile)

profiles_df = pd.DataFrame(profiles)
print(profiles_df.round(2))

print("\n" + "="*50)
print("BUSINESS INTERPRETATION:")
print("="*50)

# Business interpretation
interpretations = {
    0: "Medium Income, Medium Spending - Average Customers",
    1: "High Income, Low Spending - Conservative Spenders",
    2: "Low Income, Low Spending - Budget-Conscious",
    3: "Low Income, High Spending - Carefree Spenders",
    4: "High Income, High Spending - Premium Customers"
}

for cluster in range(optimal_k):
    print(f"Cluster {cluster}: {interpretations.get(cluster, 'Need analysis')}")

print("=== CLUSTER COMPARISON ===")

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Plot 1: Annual Income by Cluster
df.boxplot(column='Annual Income (k$)', by='Cluster', ax=axes[0])
axes[0].set_title('Annual Income Distribution by Cluster', fontweight='bold')
axes[0].set_ylabel('Annual Income (k$)')
axes[0].set_xlabel('Cluster')

# Plot 2: Spending Score by Cluster
df.boxplot(column='Spending Score (1-100)', by='Cluster', ax=axes[1])
axes[1].set_title('Spending Score Distribution by Cluster', fontweight='bold')
axes[1].set_ylabel('Spending Score (1-100)')
axes[1].set_xlabel('Cluster')

plt.suptitle('')  # Remove automatic title
plt.tight_layout()
plt.show()

print("=== SAVING RESULTS ===")

# Save the clustered data
df.to_csv('Mall_Customers_Clustered.csv', index=False)

# Download the results
files.download('Mall_Customers_Clustered.csv')

print("Clustered dataset saved and downloaded!")